# -*- coding: utf-8 -*-
"""
Created on Sun Nov 21 15:44:00 2021

@author: Leo
"""
""" Based on Ray but not using Ray """

# tf.compat.v1.disable_eager_execution()


import scipy.io as sio
import threading
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, History, ModelCheckpoint, ReduceLROnPlateau
m = 70
N = 100
Nd = 7
p = 1024
k = 2
dv = 10
alpha = 10*N
snr = 7  # training snr


def SpreadingCodeGen(N, m, Nd, dv):
    index = np.zeros((dv, N), dtype=int)
    index_list = []
    for i in range(N):
        index[:, i] = np.random.choice(m, dv, replace=False)
        index[:, i] = np.sort(index[:, i])

        index_list.append(index[:, i].tolist())
        for j in range(i):
            while index_list[j] == index_list[i]:
                index_list[j] = np.sort(np.random.choice(
                    m, dv, replace=False)).tolist()
    return index_list


def CodebookGen(N, m, Nd, dv, SC):
    Codebook = np.zeros([m, m*N*Nd], dtype=int)
    for i in range(N):
        for j in range(dv):
            for k in range(Nd):
                Codebook[SC[i][j], (SC[i][j] + k*m + m*Nd*i)] = 1
    return Codebook


# Generate spreading code for each user
SC = SpreadingCodeGen(N, m, Nd, dv)
Codebook = CodebookGen(N, m, Nd, dv, SC)

# Check if codebook is correct
for i in range(5):
    test = np.random.randint(0, 100, size=1)
    test = test[0]  # to int
    if (Codebook[SC[test][0], SC[test][0]+m*Nd*test] == 1) and (
            Codebook[SC[test][1], SC[test][1]+m*Nd*test] == 1):
        ans = "Correct"
    else:
        ans = "Failure"
    print("Codebook test: " + ans)


# Generate training data by ray
# def RayOutput():
#     # par = 4*10  # 40000 data
#     start = time.time()
#     results = [TrainingDataGen.remote(
#         N, m, Nd, dv, p, k, snr, Codebook) for x in range(1)]
#     results = ray.get(results)
#     y_hat_p = np.zeros((2*m, p))
#     active_delta_matrix = np.zeros((N, p))
#     for i in range(1):
#         for j in range(2):
#             y_hat_p[:, i*p:(i+1)*p] = results[0][0]
#             active_delta_matrix[:, i*p:(i+1)*p] = results[0][1]
#     print("duration =", time.time() - start)
#     return (y_hat_p, active_delta_matrix)

# for i in range(3):
#     (TD) = RayOutput()
#     print(i)


# Generate training data by ray with megawork
# =============================================================================
# # start = time.time()
# # y_hat_p, active_delta_matrix = (
# #     [MegaWork_TrainingData.remote(0, 10) for i in range(1)])
# # print(time.time() - start)
# # y_hat_p = ray.get(y_hat_p)
# # active_delta_matrix = ray.get(active_delta_matrix)
# =============================================================================


class threadsafe_iter:
    """Takes an iterator/generator and makes it thread-safe by
    serializing call to the `next` method of given iterator/generator.
    """

    def __init__(self, it):
        self.it = it
        self.lock = threading.Lock()

    def __iter__(self):
        return self

    def __next__(self):
        with self.lock:
            return self.it.__next__()


def threadsafe_generator(f):
    """A decorator that takes a generator function and makes it thread-safe.
    """
    def g(*a, **kw):
        return threadsafe_iter(f(*a, **kw))
    return g


@threadsafe_generator
def TrainingDataGen(N, m, Nd, dv, p, k, snr, Codebook):
    while True:
        # row: user, col: Nd symbols with m channel gains
        active_index_matrix = np.zeros((k, p), dtype='int32')   # List
        # np array generated by active_index_matrix
        active_delta_matrix = np.zeros((N, p), dtype='int32')
        y_hat_p = np.zeros((2*m, p))
        N0 = 10**(-snr/10)
        # for epoch in range(p):
        for i in range(p):
            active_index = np.random.choice(N, k, replace=False)
            active_index_matrix[:, i] = active_index
            active_delta_matrix[:, i][active_index] = 1

        x = np.zeros((m*Nd*N, p), dtype='complex128')
        for i in range(p):
            # print(i)
            x_temp = np.zeros((N, m*Nd), dtype='complex128')
            for j in (active_index_matrix[:, i]):
                bits = np.random.randint(0, 2, size=[1, Nd])*2-1
                channel = np.random.randn(1, m) + 1j*np.random.randn(1, m)
                x_temp[j, :] = np.kron(bits, channel)
            x[:, i] = x_temp.reshape(m*Nd*N,)
        y_tilde = np.dot(Codebook, x)
        noise = np.sqrt(N0/2) * (np.random.randn(*y_tilde.shape,) +
                                 1j*np.random.randn(*y_tilde.shape,))
        # noise = np.sqrt(N0/2) * np.zeros(y_tilde.shape,)    # use for check (no noise)
        y_tilde = y_tilde + noise

        y_hat_p[:m, :] = np.real(y_tilde)
        y_hat_p[m:, :] = np.imag(y_tilde)
        y_hat_p = y_hat_p.T
        active_delta_matrix = active_delta_matrix.T
        yield (y_hat_p, active_delta_matrix)
    # return y_hat_p, active_delta_matrix


# y_hat_p, active_delta_matrix = TrainingDataGen(N, m, Nd, dv, p, k, snr, Codebook)


# Time test
# start = time.time()
# y_hat_p, active_delta_matrix = TrainingDataGen(N, m, Nd, dv, 2*10**4, k, snr, Codebook)
# print("duration =", time.time() - start)

# y_hat_p = y_hat_p.T
# active_delta_matrix = active_delta_matrix.T


def Hidden_Layer(input_tensor, alpha, stage):
    """
    Parameters
    ----------
    input_tensor : Output of last layer
    alpha : Number of neuron
    stage : Index of hidden layer

    Returns output tensor
    -------
    """
    name_base = 'HL' + stage
    x = layers.Dense(alpha, name=name_base + '_1')(input_tensor)
    x = layers.BatchNormalization(name=name_base + '_2')(x)
    x = layers.Activation('relu', name=name_base + '_3')(x)
    x = layers.Dropout(0.2, name=name_base + '_4')(x)
    x = layers.add([x, input_tensor], name=name_base + '_Add')
    return x


def AUD(alpha, N):
    model_input = layers.Input(shape=[2*m, ], name='InputLayer')
    x = layers.Dense(alpha, name='InputFC')(model_input)
    x = layers.BatchNormalization(name='InputBN')(x)
    x = Hidden_Layer(x, alpha, stage='_A')
    x = Hidden_Layer(x, alpha, stage='_B')
    x = Hidden_Layer(x, alpha, stage='_C')
    x = Hidden_Layer(x, alpha, stage='_D')
    x = Hidden_Layer(x, alpha, stage='_E')
    x = Hidden_Layer(x, alpha, stage='_F')
    x = layers.Dense(N, name='OutputFC')(x)
    x = layers.Softmax(axis=-1, name='OutputActivation')(x)

    model = Model(model_input, x, name='D_AUD')
    return model


early_stopping = EarlyStopping(monitor='val_loss', patience=50)
reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5,
                              patience=10, min_lr=0.000001)

AUD1 = AUD(alpha, N)
AUD1.compile(optimizer=Adam(learning_rate=5*10**-4),
             loss='categorical_crossentropy')


AUD1.fit(TrainingDataGen(N, m, Nd, dv, p, k, snr, Codebook),  # 一次產生p筆資料
         steps_per_epoch=10,  # 一個epoch會跑training_gen七次
         epochs=1000,
         # batch_size=1024,
         # validation_split=0.3,
         validation_data=TrainingDataGen(N, m, Nd, dv, p, k, snr, Codebook),
         validation_steps=10,
         callbacks=[early_stopping, reduce_lr])
AUD1.save_weights('./sc10k2.h5')
hist_dict = AUD1.history
all_val_loss = hist_dict.history['val_loss']
all_loss = hist_dict.history['loss']


epoch = np.arange(1, len(all_loss) + 1)

plt.semilogy(epoch, all_val_loss, label='val_loss')
plt.semilogy(epoch, all_loss, label='loss')

plt.legend(loc=0)
plt.grid('true')
plt.title('Loss (dv=10, k=2)')
plt.xlabel('epochs')
plt.ylabel('Binary cross-entropy loss')


def TrainingDataGen(N, m, Nd, dv, p, k, snr, Codebook):
    # row: user, col: Nd symbols with m channel gains
    active_index_matrix = np.zeros((k, p), dtype='int32')   # List
    # np array generated by active_index_matrix
    active_delta_matrix = np.zeros((N, p), dtype='int32')
    y_hat_p = np.zeros((2*m, p))
    N0 = 10**(-snr/10)
    # for epoch in range(p):
    for i in range(p):
        active_index = np.random.choice(N, k, replace=False)
        active_index_matrix[:, i] = active_index
        active_delta_matrix[:, i][active_index] = 1

    x = np.zeros((m*Nd*N, p), dtype='complex128')
    for i in range(p):
        # print(i)
        x_temp = np.zeros((N, m*Nd), dtype='complex128')
        for j in (active_index_matrix[:, i]):
            bits = np.random.randint(0, 2, size=[1, Nd])*2-1
            channel = np.random.randn(1, m) + 1j*np.random.randn(1, m)
            x_temp[j, :] = np.kron(bits, channel)
        x[:, i] = x_temp.reshape(m*Nd*N,)
    y_tilde = np.dot(Codebook, x)
    noise = np.sqrt(N0/2) * (np.random.randn(*y_tilde.shape,) +
                             1j*np.random.randn(*y_tilde.shape,))
    # noise = np.sqrt(N0/2) * np.zeros(y_tilde.shape,)    # use for check (no noise)
    y_tilde = y_tilde + noise

    y_hat_p[:m, :] = np.real(y_tilde)
    y_hat_p[m:, :] = np.imag(y_tilde)
    y_hat_p = y_hat_p.T
    active_delta_matrix = active_delta_matrix.T
    # yield (y_hat_p, active_delta_matrix)
    return y_hat_p, active_delta_matrix


test = 10000
training_SNR = np.arange(4, 17, 2)
error_rate = np.zeros(training_SNR.shape,)
for i in range(len(training_SNR)):
    # print(i)
    y_test, p_test = TrainingDataGen(N, m, Nd, dv, test, k, snr, Codebook)
    p_hat = AUD1.predict(y_test)
    p_hat = np.argsort(-p_hat)[:, :k]
    # p_hat = (p_hat>=(1/k)).astype(int)
    temp = np.zeros([test, N], dtype='int')
    for j in range(k):
        temp[np.arange(test), p_hat[:, j]] = 1

    z = np.where((temp.reshape(test*100,)-p_test.reshape(test*100,)) != 0)
    error_rate[i] = z[0].size/(test*N)

p_succ = 1 - error_rate
plt.title('Psucc (dv=10, k=2)')
plt.grid('true')
plt.xlabel('SNR')
plt.ylabel('Psucc')
plt.semilogy(training_SNR, p_succ, marker='o')


sio.savemat('sc10k2.mat', {'SC': SC})
SC1 = sio.loadmat('SC')
SC1 = SC1['SC']
# =============================================================================
# @ray.remote
# def do_some_work(x):
#     time.sleep(np.random.uniform(0, 4)) # Replace this is with work you need to do.
#     return x
#
# def process_incremental(sum, result):
#     time.sleep(1) # Replace this with some processing code.
#     return sum + result
#
# start = time.time()
# result_ids = [do_some_work.remote(x) for x in range(4)]
# sum = 0
# while len(result_ids):
#     print('A')
#     done_id, result_ids = ray.wait(result_ids)
#     #  Return a list of IDs that are ready and a list of IDs that are not.
#     sum = process_incremental(sum, ray.get(done_id[0]))
#
#
# print("duration =", time.time() - start, "\nresult = ", sum)
# =============================================================================


# class CC():
#     def __init__(self, x, y):
#         self.x = x
#         self.y = y

#     def process(self):
#         z = self.x*self.y
#         return z

#     def ans(self):
#         return self.process() + 5
